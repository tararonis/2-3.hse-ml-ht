{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef6180WvQbD-"
      },
      "source": [
        "# Введение\n",
        "\n",
        "В этом задании Вы продолжите работать с данными из семинара [Articles Sharing and Reading from CI&T Deskdrop](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop). Если нет аккаунта на кеггле, скачать датасет можно [здесь](https://drive.google.com/file/d/1rLSr49zx6RPZIn7PV_LQr9KnnpPhrr0K/view?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSV_mxD9TciM"
      },
      "source": [
        "# Загрузка и предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "M5mH3ZolSlcm"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRQVuRvER0hd"
      },
      "source": [
        "Загрузим данные и проведем предобраотку данных как на семинаре."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "hdM1xSchR9jt"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>authorPersonId</th>\n",
              "      <th>authorSessionId</th>\n",
              "      <th>authorUserAgent</th>\n",
              "      <th>authorRegion</th>\n",
              "      <th>authorCountry</th>\n",
              "      <th>contentType</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1459193988</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-4110354420726924665</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
              "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
              "      <td>All of this work is still very early. The firs...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1459194146</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-7292285110016212249</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://cointelegraph.com/news/bitcoin-future-w...</td>\n",
              "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
              "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp       eventType            contentId       authorPersonId  \\\n",
              "1  1459193988  CONTENT SHARED -4110354420726924665  4340306774493623681   \n",
              "2  1459194146  CONTENT SHARED -7292285110016212249  4340306774493623681   \n",
              "\n",
              "       authorSessionId authorUserAgent authorRegion authorCountry contentType  \\\n",
              "1  8940341205206233829             NaN          NaN           NaN        HTML   \n",
              "2  8940341205206233829             NaN          NaN           NaN        HTML   \n",
              "\n",
              "                                                 url  \\\n",
              "1  http://www.nytimes.com/2016/03/28/business/dea...   \n",
              "2  http://cointelegraph.com/news/bitcoin-future-w...   \n",
              "\n",
              "                                               title  \\\n",
              "1  Ethereum, a Virtual Currency, Enables Transact...   \n",
              "2  Bitcoin Future: When GBPcoin of Branson Wins O...   \n",
              "\n",
              "                                                text lang  \n",
              "1  All of this work is still very early. The firs...   en  \n",
              "2  The alarm clock wakes me at 8:00 with stream o...   en  "
            ]
          },
          "execution_count": 283,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "articles_df = pd.read_csv(\"articles/shared_articles.csv\")\n",
        "articles_df = articles_df[articles_df[\"eventType\"] == \"CONTENT SHARED\"]\n",
        "articles_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "KK9wMAkvSjbk"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>personId</th>\n",
              "      <th>sessionId</th>\n",
              "      <th>userAgent</th>\n",
              "      <th>userRegion</th>\n",
              "      <th>userCountry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1465413032</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-3499919498720038879</td>\n",
              "      <td>-8845298781299428018</td>\n",
              "      <td>1264196770339959068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1465412560</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>8890720798209849691</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>3621737643587579081</td>\n",
              "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
              "      <td>NY</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp eventType            contentId             personId  \\\n",
              "0  1465413032      VIEW -3499919498720038879 -8845298781299428018   \n",
              "1  1465412560      VIEW  8890720798209849691 -1032019229384696495   \n",
              "\n",
              "             sessionId                                          userAgent  \\\n",
              "0  1264196770339959068                                                NaN   \n",
              "1  3621737643587579081  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...   \n",
              "\n",
              "  userRegion userCountry  \n",
              "0        NaN         NaN  \n",
              "1         NY          US  "
            ]
          },
          "execution_count": 284,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interactions_df = pd.read_csv(\"articles/users_interactions.csv\")\n",
        "interactions_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "5nQScdSTTzNG"
      },
      "outputs": [],
      "source": [
        "interactions_df.personId = interactions_df.personId.astype(str)\n",
        "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
        "articles_df.contentId = articles_df.contentId.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "eu6R9rDQT2P4"
      },
      "outputs": [],
      "source": [
        "# зададим словарь определяющий силу взаимодействия\n",
        "event_type_strength = {\n",
        "    \"VIEW\": 1.0,\n",
        "    \"LIKE\": 2.0,\n",
        "    \"BOOKMARK\": 2.5,\n",
        "    \"FOLLOW\": 3.0,\n",
        "    \"COMMENT CREATED\": 4.0,\n",
        "}\n",
        "\n",
        "interactions_df[\"eventStrength\"] = interactions_df.eventType.apply(\n",
        "    lambda x: event_type_strength[x]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATO5PRRwUkQ0"
      },
      "source": [
        "Оставляем только тех пользователей, которые произамодействовали более чем с пятью статьями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "d-0HoboYUBm5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# users: 1895\n",
            "# users with at least 5 interactions: 1140\n"
          ]
        }
      ],
      "source": [
        "users_interactions_count_df = (\n",
        "    interactions_df.groupby([\"personId\", \"contentId\"])\n",
        "    .first()\n",
        "    .reset_index()\n",
        "    .groupby(\"personId\")\n",
        "    .size()\n",
        ")\n",
        "print(\"# users:\", len(users_interactions_count_df))\n",
        "\n",
        "users_with_enough_interactions_df = users_interactions_count_df[\n",
        "    users_interactions_count_df >= 5\n",
        "].reset_index()[[\"personId\"]]\n",
        "print(\"# users with at least 5 interactions:\", len(users_with_enough_interactions_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQagI3DHUuX5"
      },
      "source": [
        "Оставляем только те взаимодействия, которые относятся к отфильтрованным пользователям."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "34rrdGdpUFgk"
      },
      "outputs": [],
      "source": [
        "interactions_from_selected_users_df = interactions_df.loc[\n",
        "    np.in1d(interactions_df.personId, users_with_enough_interactions_df)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "Hd3VS_BgU9HN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# interactions before: (72312, 9)\n",
            "# interactions after: (69868, 9)\n"
          ]
        }
      ],
      "source": [
        "print(f\"# interactions before: {interactions_df.shape}\")\n",
        "print(f\"# interactions after: {interactions_from_selected_users_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYpRiFkQVR6B"
      },
      "source": [
        "Объединяем все взаимодействия пользователя по каждой статье и сглаживаем полученный результат, взяв от него логарифм."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "mtPtAehKVEUu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "      <th>last_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-5065077552540450930</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1470395911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-6623581327558800021</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1487240080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-793729620925729327</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1472834892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>1469580151036142903</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1487240062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>7270966256391553686</td>\n",
              "      <td>1.584963</td>\n",
              "      <td>1485994324</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               personId             contentId  eventStrength  last_timestamp\n",
              "0  -1007001694607905623  -5065077552540450930       1.000000      1470395911\n",
              "1  -1007001694607905623  -6623581327558800021       1.000000      1487240080\n",
              "2  -1007001694607905623   -793729620925729327       1.000000      1472834892\n",
              "3  -1007001694607905623   1469580151036142903       1.000000      1487240062\n",
              "4  -1007001694607905623   7270966256391553686       1.584963      1485994324"
            ]
          },
          "execution_count": 290,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def smooth_user_preference(x):\n",
        "    return math.log(1 + x, 2)\n",
        "\n",
        "\n",
        "interactions_full_df = (\n",
        "    interactions_from_selected_users_df.groupby([\"personId\", \"contentId\"])\n",
        "    .eventStrength.sum()\n",
        "    .apply(smooth_user_preference)\n",
        "    .reset_index()\n",
        "    .set_index([\"personId\", \"contentId\"])\n",
        ")\n",
        "interactions_full_df[\"last_timestamp\"] = interactions_from_selected_users_df.groupby(\n",
        "    [\"personId\", \"contentId\"]\n",
        ")[\"timestamp\"].last()\n",
        "\n",
        "interactions_full_df = interactions_full_df.reset_index()\n",
        "interactions_full_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODJYMtnNWM5w"
      },
      "source": [
        "Разобьём выборку на обучение и контроль по времени."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "3F2CfAwoVrfo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# interactions on Train set: 29329\n",
            "# interactions on Test set: 9777\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "      <th>last_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-5065077552540450930</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1470395911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-793729620925729327</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1472834892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>-1006791494035379303</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1469129122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>-1039912738963181810</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1459376415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>-1081723567492738167</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1464054093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39099</th>\n",
              "      <td>997469202936578234</td>\n",
              "      <td>9112765177685685246</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1472479493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39100</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>-1255189867397298842</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39101</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>-401664538366009049</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39103</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>6881796783400625893</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39105</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>739747367187387064</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29329 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   personId             contentId  eventStrength  \\\n",
              "0      -1007001694607905623  -5065077552540450930            1.0   \n",
              "2      -1007001694607905623   -793729620925729327            1.0   \n",
              "6      -1032019229384696495  -1006791494035379303            1.0   \n",
              "7      -1032019229384696495  -1039912738963181810            1.0   \n",
              "8      -1032019229384696495  -1081723567492738167            2.0   \n",
              "...                     ...                   ...            ...   \n",
              "39099    997469202936578234   9112765177685685246            2.0   \n",
              "39100    998688566268269815  -1255189867397298842            1.0   \n",
              "39101    998688566268269815   -401664538366009049            1.0   \n",
              "39103    998688566268269815   6881796783400625893            1.0   \n",
              "39105    998688566268269815    739747367187387064            1.0   \n",
              "\n",
              "       last_timestamp  \n",
              "0          1470395911  \n",
              "2          1472834892  \n",
              "6          1469129122  \n",
              "7          1459376415  \n",
              "8          1464054093  \n",
              "...               ...  \n",
              "39099      1472479493  \n",
              "39100      1474567164  \n",
              "39101      1474567449  \n",
              "39103      1474567675  \n",
              "39105      1474567514  \n",
              "\n",
              "[29329 rows x 4 columns]"
            ]
          },
          "execution_count": 291,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_ts = 1475519530\n",
        "interactions_train_df = interactions_full_df.loc[\n",
        "    interactions_full_df.last_timestamp < split_ts\n",
        "].copy()\n",
        "interactions_test_df = interactions_full_df.loc[\n",
        "    interactions_full_df.last_timestamp >= split_ts\n",
        "].copy()\n",
        "\n",
        "print(f\"# interactions on Train set: {len(interactions_train_df)}\")\n",
        "print(f\"# interactions on Test set: {len(interactions_test_df)}\")\n",
        "\n",
        "interactions_train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5G3FTYOXLVg"
      },
      "source": [
        "Для удобства подсчёта качества запишем данные в формате, где строка соответствует пользователю, а столбцы будут истинными метками и предсказаниями в виде списков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "RT-_toqfXOa2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true_train</th>\n",
              "      <th>true_test</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-1007001694607905623</th>\n",
              "      <td>[-5065077552540450930, -793729620925729327]</td>\n",
              "      <td>[-6623581327558800021, 1469580151036142903, 72...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       true_train  \\\n",
              "personId                                                            \n",
              "-1007001694607905623  [-5065077552540450930, -793729620925729327]   \n",
              "\n",
              "                                                              true_test  \n",
              "personId                                                                 \n",
              "-1007001694607905623  [-6623581327558800021, 1469580151036142903, 72...  "
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interactions = (\n",
        "    interactions_train_df.groupby(\"personId\")[\"contentId\"]\n",
        "    .agg(lambda x: list(x))\n",
        "    .reset_index()\n",
        "    .rename(columns={\"contentId\": \"true_train\"})\n",
        "    .set_index(\"personId\")\n",
        ")\n",
        "\n",
        "interactions[\"true_test\"] = interactions_test_df.groupby(\"personId\")[\"contentId\"].agg(\n",
        "    lambda x: list(x)\n",
        ")\n",
        "\n",
        "# заполнение пропусков пустыми списками\n",
        "interactions.loc[pd.isnull(interactions.true_test), \"true_test\"] = [\n",
        "    \"\"\n",
        "    for x in range(\n",
        "        len(interactions.loc[pd.isnull(interactions.true_test), \"true_test\"])\n",
        "    )\n",
        "]\n",
        "\n",
        "interactions.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UWDyWKsamSa"
      },
      "source": [
        "# Библиотека LightFM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-iXjvdZa25Z"
      },
      "source": [
        "Для рекомендации Вы будете пользоваться библиотекой [LightFM](https://making.lyst.com/lightfm/docs/home.html), в которой реализованы популярные алгоритмы. Для оценивания качества рекомендации, как и на семинаре, будем пользоваться метрикой *precision@10*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "GE_chrYN2lNw"
      },
      "outputs": [],
      "source": [
        "#!pip install lightfm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "Qtyn38PZXPLf"
      },
      "outputs": [],
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjyGqulcZTf"
      },
      "source": [
        "## Задание 1 (1.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sof6V5Dd4h9"
      },
      "source": [
        "Модели в LightFM работают с разреженными матрицами. Создайте разреженные матрицы `data_train` и `data_test` (размером количество пользователей на количество статей), такие что на пересечении строки пользователя и столбца статьи стоит сила их взаимодействия, если взаимодействие было, и стоит ноль, если взаимодействия не было."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>personId</th>\n",
              "      <th>sessionId</th>\n",
              "      <th>userAgent</th>\n",
              "      <th>userRegion</th>\n",
              "      <th>userCountry</th>\n",
              "      <th>eventStrength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1465413032</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-3499919498720038879</td>\n",
              "      <td>-8845298781299428018</td>\n",
              "      <td>1264196770339959068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp eventType             contentId              personId  \\\n",
              "0  1465413032      VIEW  -3499919498720038879  -8845298781299428018   \n",
              "\n",
              "             sessionId userAgent userRegion userCountry  eventStrength  \n",
              "0  1264196770339959068       NaN        NaN         NaN            1.0  "
            ]
          },
          "execution_count": 295,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interactions_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [],
      "source": [
        "users = np.unique(interactions_df['personId'])\n",
        "articles = np.unique(interactions_df['contentId'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "sparse_matrix = pd.DataFrame(0.0, index=users, columns=articles)\n",
        "\n",
        "users_id = interactions_train_df['personId'].values\n",
        "content_id = interactions_train_df['contentId'].values\n",
        "events_strength = interactions_train_df['eventStrength'].values\n",
        "\n",
        "for i in range(len(interactions_train_df)):\n",
        "    sparse_matrix.loc[users_id[i], content_id[i]] = events_strength[i] if events_strength is not np.NAN else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " There are NaNs: False\n"
          ]
        }
      ],
      "source": [
        "print(f\" There are NaNs: {sparse_matrix.isnull().any().any()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<1895x2987 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 29329 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 299,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train = csr_matrix(sparse_matrix.values)\n",
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {},
      "outputs": [],
      "source": [
        "users = np.unique(interactions_df['personId'])\n",
        "articles = np.unique(interactions_df['contentId'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-1006791494035379303</th>\n",
              "      <th>-1021685224930603833</th>\n",
              "      <th>-1022885988494278200</th>\n",
              "      <th>-1024046541613287684</th>\n",
              "      <th>-1033806831489252007</th>\n",
              "      <th>-1038011342017850</th>\n",
              "      <th>-1039912738963181810</th>\n",
              "      <th>-1046621686880462790</th>\n",
              "      <th>-1051830303851697653</th>\n",
              "      <th>-1055630159212837930</th>\n",
              "      <th>...</th>\n",
              "      <th>9222265156747237864</th>\n",
              "      <th>943818026930898372</th>\n",
              "      <th>957332268361319692</th>\n",
              "      <th>962287586799267519</th>\n",
              "      <th>966067567430037498</th>\n",
              "      <th>967143806332397325</th>\n",
              "      <th>972258375127367383</th>\n",
              "      <th>980458131533897249</th>\n",
              "      <th>98528655405030624</th>\n",
              "      <th>991271693336573226</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-1007001694607905623</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1032019229384696495</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-108842214936804958</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 2987 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      -1006791494035379303  -1021685224930603833  \\\n",
              "-1007001694607905623                   0.0                   0.0   \n",
              "-1032019229384696495                   0.0                   0.0   \n",
              "-108842214936804958                    0.0                   0.0   \n",
              "\n",
              "                      -1022885988494278200  -1024046541613287684  \\\n",
              "-1007001694607905623                   0.0                   0.0   \n",
              "-1032019229384696495                   0.0                   0.0   \n",
              "-108842214936804958                    0.0                   0.0   \n",
              "\n",
              "                      -1033806831489252007  -1038011342017850  \\\n",
              "-1007001694607905623                   0.0                0.0   \n",
              "-1032019229384696495                   0.0                0.0   \n",
              "-108842214936804958                    0.0                0.0   \n",
              "\n",
              "                      -1039912738963181810  -1046621686880462790  \\\n",
              "-1007001694607905623                   0.0                   0.0   \n",
              "-1032019229384696495                   0.0                   0.0   \n",
              "-108842214936804958                    0.0                   0.0   \n",
              "\n",
              "                      -1051830303851697653  -1055630159212837930  ...  \\\n",
              "-1007001694607905623                   0.0                   0.0  ...   \n",
              "-1032019229384696495                   0.0                   0.0  ...   \n",
              "-108842214936804958                    0.0                   0.0  ...   \n",
              "\n",
              "                      9222265156747237864  943818026930898372  \\\n",
              "-1007001694607905623                  0.0                 0.0   \n",
              "-1032019229384696495                  0.0                 0.0   \n",
              "-108842214936804958                   0.0                 0.0   \n",
              "\n",
              "                      957332268361319692  962287586799267519  \\\n",
              "-1007001694607905623                 0.0                 0.0   \n",
              "-1032019229384696495                 0.0                 0.0   \n",
              "-108842214936804958                  0.0                 0.0   \n",
              "\n",
              "                      966067567430037498  967143806332397325  \\\n",
              "-1007001694607905623                 0.0                 0.0   \n",
              "-1032019229384696495                 0.0                 0.0   \n",
              "-108842214936804958                  0.0                 0.0   \n",
              "\n",
              "                      972258375127367383  980458131533897249  \\\n",
              "-1007001694607905623                 0.0                 0.0   \n",
              "-1032019229384696495                 0.0                 0.0   \n",
              "-108842214936804958                  0.0                 0.0   \n",
              "\n",
              "                      98528655405030624  991271693336573226  \n",
              "-1007001694607905623                0.0                 0.0  \n",
              "-1032019229384696495                0.0                 0.0  \n",
              "-108842214936804958                 0.0                 0.0  \n",
              "\n",
              "[3 rows x 2987 columns]"
            ]
          },
          "execution_count": 301,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sparse_matrix = pd.DataFrame(0.0, index=users, columns=articles)\n",
        "\n",
        "users_id = interactions_test_df['personId'].values\n",
        "content_id = interactions_test_df['contentId'].values\n",
        "events_strength = interactions_test_df['eventStrength'].values\n",
        "\n",
        "for i in range(len(interactions_test_df)):\n",
        "    sparse_matrix.loc[users_id[i], content_id[i]] = events_strength[i] if events_strength is not np.nan else 0\n",
        "\n",
        "sparse_matrix.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " There are NaNs: False\n"
          ]
        }
      ],
      "source": [
        "print(f\" There are NaNs: {sparse_matrix.isnull().any().any()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<1895x2987 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 9777 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 303,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_test = csr_matrix(sparse_matrix.values)\n",
        "data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiNGVzTveRXE"
      },
      "source": [
        "## Задание 2 (0.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPfVK3STeryM"
      },
      "source": [
        "Обучите модель LightFM с `loss=\"warp\"` и посчитайте *precision@10* на тесте."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "YFQxeHw8eVLz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.004276986"
            ]
          },
          "execution_count": 304,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.datasets import fetch_movielens\n",
        "from lightfm.evaluation import precision_at_k\n",
        "\n",
        "\n",
        "model = LightFM(loss=\"warp\", random_state=42)\n",
        "model.fit(data_train, epochs=50, num_threads=2)\n",
        "\n",
        "\n",
        "precision = precision_at_k(model, data_test, k=10).mean()\n",
        "precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ¯\\_(ツ)_/¯"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZDsG1iAfdrl"
      },
      "source": [
        "## Задание 3 (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F93chvtbgA9N"
      },
      "source": [
        "При вызове метода `fit` LightFM позволяет передавать в `item_features` признаковое описание объектов. Воспользуемся этим. Будем получать признаковое описание из текста статьи в виде [TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF) (можно воспользоваться `TfidfVectorizer` из scikit-learn). Создайте матрицу `feat` размером количесвто статей на размер признакового описание и обучите LightFM с `loss=\"warp\"` и посчитайте precision@10 на тесте."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>authorPersonId</th>\n",
              "      <th>authorSessionId</th>\n",
              "      <th>authorUserAgent</th>\n",
              "      <th>authorRegion</th>\n",
              "      <th>authorCountry</th>\n",
              "      <th>contentType</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1459193988</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-4110354420726924665</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
              "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
              "      <td>All of this work is still very early. The firs...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp       eventType             contentId       authorPersonId  \\\n",
              "1  1459193988  CONTENT SHARED  -4110354420726924665  4340306774493623681   \n",
              "\n",
              "       authorSessionId authorUserAgent authorRegion authorCountry contentType  \\\n",
              "1  8940341205206233829             NaN          NaN           NaN        HTML   \n",
              "\n",
              "                                                 url  \\\n",
              "1  http://www.nytimes.com/2016/03/28/business/dea...   \n",
              "\n",
              "                                               title  \\\n",
              "1  Ethereum, a Virtual Currency, Enables Transact...   \n",
              "\n",
              "                                                text lang  \n",
              "1  All of this work is still very early. The firs...   en  "
            ]
          },
          "execution_count": 305,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "articles_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "id": "5SvUi_Fofgf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0034623218"
            ]
          },
          "execution_count": 306,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(articles_df.text)\n",
        "\n",
        "item_features = tfidf_matrix\n",
        "\n",
        "model = LightFM(loss='warp', random_state=42)\n",
        "model.fit(data_train, item_features=item_features, epochs=40, num_threads=4)\n",
        "\n",
        "precision = precision_at_k(model, data_test, item_features=item_features, k=10).mean()\n",
        "precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> улучшилось, добавим title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title_and_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      title_and_text\n",
              "1  Ethereum, a Virtual Currency, Enables Transact..."
            ]
          },
          "execution_count": 307,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat = pd.DataFrame({\n",
        "    'title_and_text': articles_df['title'].str.cat(articles_df['text'], sep=' ')\n",
        "})\n",
        "feat.columns = ['title_and_text']\n",
        "\n",
        "feat.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.00407332"
            ]
          },
          "execution_count": 308,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(feat.title_and_text)\n",
        "\n",
        "item_features = tfidf_matrix\n",
        "\n",
        "model = LightFM(loss='warp', random_state=42)\n",
        "model.fit(data_train, item_features=item_features, epochs=40, num_threads=4)\n",
        "\n",
        "precision = precision_at_k(model, data_test, item_features=item_features, k=10).mean()\n",
        "precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> я ожидал большего"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lwuex6PpsFw"
      },
      "source": [
        "## Задание 4 (1.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aZcHjSzp2cZ"
      },
      "source": [
        "В задании 3 мы использовали сырой текст статей. В этом задании необходимо сначала сделать предобработку текста (привести к нижнему регистру, убрать стоп слова, привести слова к номральной форме и т.д.), после чего обучите модель и оценить качество на тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import spacy # просто потому что могу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/choosen-\n",
            "[nltk_data]     one/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/choosen-\n",
            "[nltk_data]     one/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/choosen-\n",
            "[nltk_data]     one/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 310,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['arabic',\n",
              " 'azerbaijani',\n",
              " 'basque',\n",
              " 'bengali',\n",
              " 'catalan',\n",
              " 'chinese',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'greek',\n",
              " 'hebrew',\n",
              " 'hinglish',\n",
              " 'hungarian',\n",
              " 'indonesian',\n",
              " 'italian',\n",
              " 'kazakh',\n",
              " 'nepali',\n",
              " 'norwegian',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'slovene',\n",
              " 'spanish',\n",
              " 'swedish',\n",
              " 'tajik',\n",
              " 'turkish']"
            ]
          },
          "execution_count": 312,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['en', 'pt', 'es', 'la', 'ja'], dtype=object)"
            ]
          },
          "execution_count": 313,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "articles_df['lang'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english') + stopwords.words('portuguese') + stopwords.words('spanish'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):    \n",
        "    text = text.lower() \n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]   \n",
        "  \n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]    \n",
        "\n",
        "    normalized_tokens = []\n",
        "    for token in lemmatized_tokens:\n",
        "        doc = nlp(token)\n",
        "        normalized_tokens.append(doc[0].lemma_)    \n",
        "\n",
        "    preprocessed_text = ' '.join(normalized_tokens)\n",
        "    \n",
        "    return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat['title_and_text'] = feat['title_and_text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(feat.title_and_text)\n",
        "\n",
        "item_features = tfidf_matrix\n",
        "\n",
        "model = LightFM(loss='warp', random_state=42)\n",
        "model.fit(data_train, item_features=item_features, epochs=40, num_threads=4)\n",
        "\n",
        "precision = precision_at_k(model, data_test, item_features=item_features, k=10).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.004480652"
            ]
          },
          "execution_count": 271,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgayAPRpqn7L"
      },
      "source": [
        "Улучшилось ли качество предсказания?\n",
        "> увы - нет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text2(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat2 = pd.DataFrame({\n",
        "    'title_and_text': articles_df['title'].str.cat(articles_df['text'], sep=' ')\n",
        "})\n",
        "feat2.columns = ['title_and_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat2['title_and_text'] = feat2['title_and_text'].apply(preprocess_text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(feat2.title_and_text)\n",
        "\n",
        "item_features2 = tfidf_matrix\n",
        "\n",
        "model = LightFM(loss='warp', random_state=42)\n",
        "model.fit(data_train, item_features=item_features2, epochs=40, num_threads=4)\n",
        "\n",
        "precision = precision_at_k(model, data_test, item_features=item_features2, k=10).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0048879837"
            ]
          },
          "execution_count": 319,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKRzLLodq3gq"
      },
      "source": [
        "## Задание 5 (1.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjHl49Aq8su"
      },
      "source": [
        "Подберите гиперпараметры модели LightFM (`n_components` и др.) для улучшения качества модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "id": "PlwaeCiZqncD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/choosen-one/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/home/choosen-one/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 980, in _score\n",
            "    scores = scorer(estimator, X_test, **score_params)\n",
            "  File \"/tmp/ipykernel_23773/3699135485.py\", line 8, in precision_scorer\n",
            "    return precision_at_k(estimator, X, k=k).mean()\n",
            "  File \"/home/choosen-one/.local/lib/python3.10/site-packages/lightfm/evaluation.py\", line 71, in precision_at_k\n",
            "    ranks = model.predict_rank(\n",
            "  File \"/home/choosen-one/.local/lib/python3.10/site-packages/lightfm/lightfm.py\", line 954, in predict_rank\n",
            "    raise ValueError(\"Incorrect number of features in item_features\")\n",
            "ValueError: Incorrect number of features in item_features\n",
            "\n",
            "  warnings.warn(\n",
            "/home/choosen-one/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'learning_rate': 0.01, 'loss': 'warp', 'no_components': 1}\n",
            "Precision@10 with best parameters: 0.0030549897\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'no_components': (1, 30),\n",
        "    'learning_rate': (0.01, 0.15),    \n",
        "    'loss': ['warp', 'bpr']\n",
        "}\n",
        "\n",
        "def precision_scorer(estimator, X, k=10):\n",
        "    return precision_at_k(estimator, X, k=k).mean()\n",
        "\n",
        "# Создание объекта GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring=precision_scorer)\n",
        "\n",
        "# Поиск лучших параметров\n",
        "grid_search.fit(data_train, item_features=item_features2, epochs=40)\n",
        "\n",
        "# Вывод лучших параметров\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Оценка модели с лучшими параметрами\n",
        "precision = precision_at_k(grid_search.best_estimator_, data_test, item_features=item_features2, k=10).mean()\n",
        "print(\"Precision@10 with best parameters:\", precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> С гридсеарч получилась еренду - воспользуемся байесовской оптимизацией"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Incorrect number of features in item_features",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[326], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mscore\n\u001b[1;32m     16\u001b[0m param_space \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m),                    \u001b[38;5;66;03m# num_components\u001b[39;00m\n\u001b[1;32m     17\u001b[0m                (\u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog-uniform\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;66;03m# learning_rate\u001b[39;00m\n\u001b[1;32m     18\u001b[0m                (\u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog-uniform\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;66;03m# item_alpha               \u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_optimization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mНаилучшие гиперпараметры:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЛучшее значение метрики (precision_at_k):\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39mresult\u001b[38;5;241m.\u001b[39mfun)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/optimizer/gp.py:281\u001b[0m, in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[1;32m    277\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[1;32m    278\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    279\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/optimizer/base.py:332\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[1;32m    331\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[0;32m--> 332\u001b[0m     next_y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     result \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtell(next_x, next_y)\n\u001b[1;32m    334\u001b[0m     result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n",
            "Cell \u001b[0;32mIn[326], line 13\u001b[0m, in \u001b[0;36mf_optimization\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m LightFM(no_components\u001b[38;5;241m=\u001b[39mnum_components,\n\u001b[1;32m      8\u001b[0m                 learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m      9\u001b[0m                 item_alpha\u001b[38;5;241m=\u001b[39mitem_alpha)                   \n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(data_train, item_features\u001b[38;5;241m=\u001b[39mitem_features2, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_at_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()   \n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mscore\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightfm/evaluation.py:71\u001b[0m, in \u001b[0;36mprecision_at_k\u001b[0;34m(model, test_interactions, train_interactions, k, user_features, item_features, preserve_rows, num_threads, check_intersections)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_threads \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of threads must be 1 or larger.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m ranks \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_rank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_interactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_interactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_interactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_intersections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_intersections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m ranks\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mless(ranks\u001b[38;5;241m.\u001b[39mdata, k, ranks\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     82\u001b[0m precision \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(np\u001b[38;5;241m.\u001b[39marray(ranks\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))) \u001b[38;5;241m/\u001b[39m k\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightfm/lightfm.py:954\u001b[0m, in \u001b[0;36mLightFM.predict_rank\u001b[0;34m(self, test_interactions, train_interactions, item_features, user_features, num_threads, check_intersections)\u001b[0m\n\u001b[1;32m    949\u001b[0m (user_features, item_features) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_feature_matrices(\n\u001b[1;32m    950\u001b[0m     n_users, n_items, user_features, item_features\n\u001b[1;32m    951\u001b[0m )\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m item_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 954\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect number of features in item_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect number of features in user_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: Incorrect number of features in item_features"
          ]
        }
      ],
      "source": [
        "from skopt import gp_minimize\n",
        "\n",
        "\n",
        "def f_optimization(params):\n",
        "    num_components, learning_rate, item_alpha = params\n",
        "\n",
        "    model = LightFM(no_components=num_components,\n",
        "                    learning_rate=learning_rate,\n",
        "                    item_alpha=item_alpha)                   \n",
        "\n",
        "    model.fit(data_train, item_features=item_features2, epochs=40)\n",
        "    \n",
        "    score = precision_at_k(model, data_test, k=10).mean()   \n",
        "    return -score\n",
        "\n",
        "param_space = [(1, 100),                    # num_components\n",
        "               (0.0001, 0.1, 'log-uniform'), # learning_rate\n",
        "               (0.0001, 0.1, 'log-uniform')] # item_alpha               \n",
        "\n",
        "\n",
        "result = gp_minimize(f_optimization,              \n",
        "                     dimensions=param_space,  \n",
        "                     n_calls=200,             \n",
        "                     random_state=42) \n",
        "\n",
        "print(\"Наилучшие гиперпараметры:\", result.x)\n",
        "print(\"Лучшее значение метрики (precision_at_k):\", -result.fun)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJA7v07NrYSF"
      },
      "source": [
        "## Задание 6 (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veLFUoVRrisk"
      },
      "source": [
        "Реализуйте функции для вычисления следующих метрик:\n",
        "* precision@k\n",
        "* recall@k\n",
        "* NDCG@k\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "CQmn1cb-rXU3"
      },
      "outputs": [],
      "source": [
        "# Ваш код здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE5L-ise3Bq_"
      },
      "source": [
        "## Задание 7 (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bqmjJMH3DB7"
      },
      "source": [
        "Вычислите значения реализованных метрик для $k=10$ для лучшей полученной модели в предыдущих шагах.\n",
        "\n",
        "Найдите уже реализованные варианты этих метрик в библиотеках lightfm и sklearn. Сравните полученные у вас значения метрик с результатами встроенных в библиотеки метрик."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "Vs3x2O5Z3Cgo"
      },
      "outputs": [],
      "source": [
        "# Ваш код здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t78oSTQz3Y6u"
      },
      "source": [
        "## Задание 8 (1 балл)\n",
        "\n",
        "Реализуйте алгоритм ALS и примените его для решения задачи ноутбука."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voZ9GsE54EZT"
      },
      "source": [
        "**ALS**\n",
        "\n",
        "Итак, поставлена задача построения модели со скрытыми переменными (latent factor model) для коллаборативной фильтрации:\n",
        "\n",
        "$$ \\sum_{u,i} (r_{ui} - \\langle p_u, q_i \\rangle)^2 \\to \\min_{P,Q}$$\n",
        "\n",
        "Суммирование ведется по всем парам $(u, i),$ для которых известен рейтинг $r_{ui}$ (и только по ним), а $p_u, q_i$ – латентные представления пользователя~$u$ и товара $i$, соответственно, матрицы $P, Q$ получаются путем записывания по столбцам векторов $p_u, q_i$ соответственно.\n",
        "\n",
        "Подход ALS (Alternating Least Squares) решает задачу, попеременно фиксируя матрицы $P$ и $Q$, — оказывается, что, зафиксировав одну из матриц, можно выписать аналитическое решение задачи для другой.\n",
        "\n",
        "$$\\nabla_{p_u} \\bigg[ \\sum_{u,i} (r_{ui} - \\langle p_u, q_i \\rangle)^2 \\bigg] = \\sum_{i} 2(r_{ui} - \\langle p_u, q_i \\rangle)q_i = 0$$\n",
        "\n",
        "Воспользовавшись тем, что $a^Tbc = cb^Ta$, получим\n",
        "$$\\sum_{i} r_{ui}q_i - \\sum_i q_i q_i^T p_u = 0.$$\n",
        "\n",
        "Тогда окончательно каждый столбец матрицы $P$ можно найти по формуле\n",
        "$$p_u = \\bigg( \\sum_i q_i q_i^T\\bigg)^{-1}\\sum_ir_{ui}q_i \\;\\; \\forall u,$$\n",
        "\n",
        "аналогично для столбцов матрицы $Q$\n",
        "$$q_i = \\bigg( \\sum_u p_u p_u^T\\bigg)^{-1}\\sum_ur_{ui}p_u \\;\\; \\forall i.$$\n",
        "\n",
        "Таким образом мы можем решать оптимизационную задачу, поочередно фиксируя одну из матриц $P$ или $Q$ и проводя оптимизацию по второй.\n",
        "\n",
        "**Оригинальная статья c постановкой задачи для ALS на explicit feedback:**\n",
        "\n",
        "* Bell, R.M. and Koren, Y., 2007, October. Scalable collaborative filtering with jointly derived neighborhood interpolation weights. In Seventh IEEE international conference on data mining (ICDM 2007) (pp. 43-52). IEEE.\n",
        "\n",
        "**Оригинальная статья с ALS для implicit данных, которая стала более известной:**\n",
        "\n",
        "* Hu, Y., Koren, Y. and Volinsky, C., 2008, December. Collaborative filtering for implicit feedback datasets. In 2008 Eighth IEEE international conference on data mining (pp. 263-272). Ieee.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "7cDRmFLs4DnT"
      },
      "outputs": [],
      "source": [
        "# Ваш код здесь"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
